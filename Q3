from sklearn.datasets import load_diabetes
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

# Load the dataset
diabetes = load_diabetes()

# Convert to a pandas DataFrame for easier manipulation
df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)

# Add the target variable
df['target'] = diabetes.target

# Display the first 5 rows
display(df.head())

# Assuming 'target' is the column you want to predict
X = df.drop('target', axis=1)
y = df['target']

# Split the data into training and testing sets (e.g., 80/20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training data shape (X_train):", X_train.shape)
print("Testing data shape (X_test):", X_test.shape)
print("Training target shape (y_train):", y_train.shape)
print("Testing target shape (y_test):", y_test.shape)

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the testing data using the fitted scaler
X_test_scaled = scaler.transform(X_test)

print("Scaled training data shape:", X_train_scaled.shape)
print("Scaled testing data shape:", X_test_scaled.shape)

# Define the shallow model
shallow_model = keras.Sequential([
    keras.layers.Input(shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(1) # Output layer for regression
])

# Compile the shallow model
shallow_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the shallow model
shallow_history = shallow_model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, verbose=0)

print("Shallow model training finished.")

# Define the deep model
deep_model = keras.Sequential([
    keras.layers.Input(shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1) # Output layer for regression
])

# Compile the deep model
deep_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the deep model
deep_history = deep_model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, verbose=0)

print("Deep model training finished.")

# Evaluate the shallow model on the test data
shallow_loss, shallow_mae = shallow_model.evaluate(X_test_scaled, y_test, verbose=0)

print(f"Shallow Model Test Loss (MSE): {shallow_loss:.4f}")
print(f"Shallow Model Test MAE: {shallow_mae:.4f}")

# Evaluate the deep model on the test data
deep_loss, deep_mae = deep_model.evaluate(X_test_scaled, y_test, verbose=0)

print(f"Deep Model Test Loss (MSE): {deep_loss:.4f}")
print(f"Deep Model Test MAE: {deep_mae:.4f}")

# Plot training history for the shallow model
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(shallow_history.history['loss'], label='Train Loss (Shallow)')
plt.plot(shallow_history.history['val_loss'], label='Validation Loss (Shallow)')
plt.title('Shallow Model Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.legend()

plt.tight_layout()
plt.show()

# Plot training history for the deep model
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(deep_history.history['loss'], label='Train Loss (Deep)')
plt.plot(deep_history.history['val_loss'], label='Validation Loss (Deep)')
plt.title('Deep Model Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.legend()

plt.tight_layout()
plt.show()
